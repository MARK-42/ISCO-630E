{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "import functools\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 64\n",
    "width = 64\n",
    "original = os.path.join('dataset','photos')\n",
    "new = os.path.join('dataset','compressed')\n",
    "files=os.listdir(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize images\n",
    "for file in files:    \n",
    "    path =  os.path.join(original,file)\n",
    "    new_path = os.path.join(new, file)\n",
    "    image = Image.open(path)\n",
    "    image = image.resize((height,width), Image.ANTIALIAS)   \n",
    "    image.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all images from the reduced dataset, and construct the dataset\n",
    "Y = [] # output\n",
    "Yid = {} # name to number Y_values\n",
    "Yname = {} # nuber to name Y_inverse_values \n",
    "\n",
    "X = [] # training dataset R\n",
    "files=os.listdir(new)\n",
    "\n",
    "for file in files:    \n",
    "    # for X\n",
    "    image_path=os.path.join(new, file)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image.flatten()\n",
    "    X.append(image)\n",
    "    # for Y\n",
    "    name = file.split(\"_\")[0]\n",
    "    if(name not in Yid) :\n",
    "        val = len(Yid) + 1\n",
    "        Yid[name] = val\n",
    "        Yname[val] = name\n",
    "    Y.append(Yid[name])\n",
    "        \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_intensities\n",
    "u = np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing data\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "\n",
    "percent = 80 \n",
    "sample_size = int((percent / float(100)) * X.shape[0])\n",
    "training_indices = random.sample(range(0, X.shape[0]), sample_size)\n",
    "for i in range(X.shape[0]) :\n",
    "    if(i in training_indices) :\n",
    "        X_train.append(X[i])\n",
    "        Y_train.append(Y[i])\n",
    "    else :\n",
    "        X_test.append(X[i])\n",
    "        Y_test.append(Y[i])\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising training dataset\n",
    "utrain = np.mean(X_train,axis=0)\n",
    "X_train = X_train - utrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising testing dataset\n",
    "X_test_original = deepcopy(X_test)\n",
    "utest = np.mean(X_test,axis=0)\n",
    "X_test = X_test - utest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding covariance matrix \n",
    "covariance = (1 / float(X_train.shape[0])) * np.dot(np.transpose(X_train), X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding best K values\n",
    "\n",
    "u, s, v = np.linalg.svd(covariance)\n",
    "totalsum = 0\n",
    "for i in range(s.shape[0]) :\n",
    "    totalsum = totalsum + s[i]\n",
    "sm = 0\n",
    "for i in range(s.shape[0]) :\n",
    "    sm = sm + s[i]\n",
    "    val = float(sm) / float(totalsum)\n",
    "    if(val >= 0.99) :\n",
    "        K=i+1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating eigen vectors\n",
    "EigenVectors = []\n",
    "for i in range(K) :\n",
    "    EigenVectors.append(u[: ,i])\n",
    "EigenVectors = np.array(EigenVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 4096)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EigenVectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4096)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the eigen faces\n",
    "eigen_faces = np.dot(X_train, np.transpose(EigenVectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing data => already done mean normalization\n",
    "projected_data = np.dot(X_test, np.transpose(EigenVectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will work with reduced dimension data\n",
    "\n",
    "X_train_original = deepcopy(X_train)\n",
    "X_test_original_1 = deepcopy(X_test)\n",
    "\n",
    "X_train = eigen_faces\n",
    "X_test = projected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean vectors\n",
    "\n",
    "mean_vectors = []\n",
    "for i in range(1, len(Yid) + 1) :\n",
    "    mean_vectors.append(np.mean(X_train[Y_train == i], axis = 0))\n",
    "mean_vectors = np.array(mean_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within class scatter\n",
    "\n",
    "S_W = np.zeros((K, K))\n",
    "for i in range(1, mean_vectors.shape[0] + 1) :\n",
    "    class_sc_mat = np.zeros((K, K))\n",
    "    for row in X_train[Y_train == i] :\n",
    "        row1, mean1 = row.reshape(K, 1), mean_vectors[i - 1].reshape(K, 1)\n",
    "        class_sc_mat += np.dot((row1 - mean1), np.transpose(row1 - mean1))\n",
    "    S_W += class_sc_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# between class scatter\n",
    "\n",
    "overall_mean = np.mean(X_train, axis = 0)\n",
    "\n",
    "S_B = np.zeros((K, K))\n",
    "for i in range(1, mean_vectors.shape[0] + 1) :\n",
    "    n = X_train[Y_train == i].shape[0]\n",
    "    mean1 = mean_vectors[i - 1].reshape(K, 1)\n",
    "    overall_mean1 = overall_mean.reshape(K, 1)\n",
    "    S_B += n * np.dot((mean1 - overall_mean1), np.transpose(mean1 - overall_mean1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = np.dot(np.linalg.inv(S_W), S_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_K = 30\n",
    "W = []\n",
    "\n",
    "for i in range(new_K) :\n",
    "    W.append(u[:, i])\n",
    "W = np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = np.dot(X_train, np.transpose(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = np.dot(X_test, np.transpose(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction \n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(X_test_transformed.shape[0]) :\n",
    "    min_distance = -1\n",
    "    for j in range(X_train_transformed.shape[0]) :\n",
    "        distance = np.linalg.norm(X_train_transformed[j] - X_test_transformed[i]) \n",
    "        if(min_distance == -1 or min_distance > distance) :\n",
    "            min_distance = distance\n",
    "            label = Y_train[j]\n",
    "    predictions.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 8, 3, 3, 3, 4, 4, 6, 5, 6, 7, 8, 9, 9, 9, 9, 10, 10, 10]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  2,  3,  3,  3,  4,  4,  6,  6,  6,  7,  8,  9,  9,  9,  9,\n",
       "       10, 10, 10])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: Arpit , predictions: Arpit\n",
      "actual: Divyansh , predictions: Divyansh\n",
      "actual: Divyansh , predictions: shashwat\n",
      "actual: Ishan , predictions: Ishan\n",
      "actual: Ishan , predictions: Ishan\n",
      "actual: Ishan , predictions: Ishan\n",
      "actual: Ishita , predictions: Ishita\n",
      "actual: Ishita , predictions: Ishita\n",
      "actual: Saumya , predictions: Saumya\n",
      "actual: Saumya , predictions: Ritik\n",
      "actual: Saumya , predictions: Saumya\n",
      "actual: shantam , predictions: shantam\n",
      "actual: shashwat , predictions: shashwat\n",
      "actual: Shivansh , predictions: Shivansh\n",
      "actual: Shivansh , predictions: Shivansh\n",
      "actual: Shivansh , predictions: Shivansh\n",
      "actual: Shivansh , predictions: Shivansh\n",
      "actual: yash , predictions: yash\n",
      "actual: yash , predictions: yash\n",
      "actual: yash , predictions: yash\n"
     ]
    }
   ],
   "source": [
    "#prediction v/s actual\n",
    "for i in range(X_test.shape[0]):\n",
    "    print(\"actual: \" +Yname[Y_test[i]] +\" , predictions: \" + Yname[predictions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct Predictions:  18  Out of:  20\n",
      "percentage accuracy:  90.0\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in range(X_test.shape[0]):\n",
    "    if predictions[i]==Y_test[i]:\n",
    "        correct+=1\n",
    "print(\"correct Predictions: \" ,(correct) , \" Out of: \",(X_test.shape[0]))\n",
    "print(\"percentage accuracy: \", (correct / X_test.shape[0]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
