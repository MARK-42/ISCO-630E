{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "def extract_data() :\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    data_file = open(\"housing.csv\")\n",
    "    data_reader = csv.reader(data_file)\n",
    "    \n",
    "    row_count = 0\n",
    "    for row in data_reader :\n",
    "        row_count += 1\n",
    "        if(row_count != 1) :\n",
    "            Y.append(float(row[1])) # price\n",
    "            data_row = [float(1)]\n",
    "            for i in range(2, len(row)) :\n",
    "                if(row[i] == \"yes\" or row[i] == \"no\") :\n",
    "                    if(row[i] == \"yes\") :\n",
    "                        data_row.append(float(1))\n",
    "                    else :\n",
    "                        data_row.append(float(0))\n",
    "                else :\n",
    "                    data_row.append(float(row[i]))\n",
    "            X.append(data_row)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# linear regression regularized functions\n",
    "# cost function linear regression regularized\n",
    "def cost_function_LR_reg(X, Y, theta, reg_lambda) :\n",
    "    sample_count = float(X.shape[0])\n",
    "    reg_sum = (reg_lambda / (float(2) * sample_count)) * np.sum(np.square(theta[1:]))\n",
    "    return (float(1) / (float(2) * sample_count)) * float(np.dot(np.transpose(np.dot(X, theta) - Y) , np.dot(X, theta) - Y)) + reg_sum\n",
    "\n",
    "# gradient descent linear regression regularized\n",
    "def gradient_descent_LR_reg(X, Y, theta, alpha, threshold, reg_lambda) :\n",
    "    costs = [cost_function_LR_reg(X, Y, theta, reg_lambda)]\n",
    "    iterations = [1]\n",
    "    sample_count = float(X.shape[0])\n",
    "    iteration_count = 2\n",
    "    \n",
    "    while(True):\n",
    "        reg_term = (reg_lambda / sample_count) * theta\n",
    "        reg_term[0] = 0\n",
    "        theta = theta - ((alpha / sample_count) * np.dot(np.transpose(X), np.dot(X, theta) - Y) + reg_term)\n",
    "        \n",
    "        current_cost = cost_function_LR_reg(X, Y, theta, reg_lambda)\n",
    "        prev_cost = costs[iteration_count - 2]\n",
    "        costs.append(current_cost)\n",
    "        iterations.append(iteration_count)\n",
    "        \n",
    "        if(prev_cost - current_cost <= threshold) :\n",
    "            break\n",
    "            \n",
    "        iteration_count = iteration_count + 1\n",
    "    \n",
    "    display_graph(costs, iterations)    # display graph \n",
    "    return theta\n",
    "\n",
    "# initialize theta\n",
    "def init_theta_LR_reg(X) :\n",
    "    return np.zeros(X.shape[1])\n",
    "    \n",
    "# normal equation \n",
    "def normal_equation_reg(X, Y, reg_lambda) :\n",
    "    reg_term = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for i in range(1, X.shape[1]) :\n",
    "        reg_term[i][i] = reg_lambda\n",
    "    \n",
    "    return np.dot(np.linalg.inv(np.dot(np.transpose(X), X) + reg_term), np.dot(np.transpose(X), Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locally weighted regression functions\n",
    "# get local weights\n",
    "def get_weights(X, input_var, LWRBand) :\n",
    "    sample_count = (X.shape[0])\n",
    "    weights = np.zeros((sample_count, sample_count))\n",
    "    for i in range(sample_count) :\n",
    "        weights[i][i] = np.exp((float(-1/2) * np.dot(np.transpose(X[i] - input_var), (X[i] - input_var))) / (LWRBand * LWRBand))\n",
    "    return weights\n",
    "\n",
    "# LWR cost\n",
    "def LWRCost(X, Y, theta, W, reg_lambda):\n",
    "    sample_count = float(X.shape[0])\n",
    "    reg_sum = (reg_lambda / (float(2) * sample_count)) * np.sum(np.square(theta[1:]))\n",
    "    return np.dot(np.dot(np.transpose(np.dot(X, theta) - Y), W), (np.dot(X, theta) - Y)) + reg_sum\n",
    "# initialize theta\n",
    "def init_theta_LWR(X) :\n",
    "    return np.zeros(X.shape[1])\n",
    "\n",
    "# gradient descent\n",
    "def LWRGD(X, Y, theta, alpha, W, threshold, reg_lambda) :\n",
    "    costs = [LWRCost(X, Y, theta, W, reg_lambda)]\n",
    "    iterations = [1]\n",
    "    sample_count = float(X.shape[0])\n",
    "    iteration_count = 2\n",
    "    \n",
    "    while(True):\n",
    "        reg_term = (reg_lambda) * theta\n",
    "        reg_term[0] = 0\n",
    "        sample_count = X.shape[0]\n",
    "        theta = theta - (alpha / sample_count) * (np.dot(np.dot(np.transpose(X), W), np.dot(X, theta) - Y) + reg_term)\n",
    "        \n",
    "        current_cost = LWRCost(X, Y, theta, W, reg_lambda)\n",
    "        prev_cost = costs[iteration_count - 2]\n",
    "        if(iteration_count % 100 == 0) :\n",
    "            print(iteration_count, prev_cost, current_cost, prev_cost - current_cost)\n",
    "        costs.append(current_cost)\n",
    "        iterations.append(iteration_count)\n",
    "        \n",
    "        if(prev_cost - current_cost <= threshold) :\n",
    "            break\n",
    "            \n",
    "        iteration_count = iteration_count + 1\n",
    "    \n",
    "    print(\"Total iterations: \", iteration_count)\n",
    "    display_graph(costs, iterations)    # display graph \n",
    "    return theta\n",
    "\n",
    "# display graph\n",
    "def display_graph(costs, iterations) :\n",
    "    plt.plot(iterations, costs)\n",
    "\n",
    "# normal equation\n",
    "def LWR_Normal(X, W, Y) :\n",
    "    reg_term = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for i in range(1, X.shape[1]) :\n",
    "        reg_term[i][i] = reg_lambda\n",
    "    val1 = np.linalg.inv(np.dot(np.dot(np.transpose(X), W), X) + reg_term)\n",
    "    val2 = np.dot(np.dot(np.transpose(X), W), Y)\n",
    "    \n",
    "    return np.dot(val1, val2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize global variables\n",
    "X, Y = extract_data()\n",
    "alpha = 10000000000\n",
    "threshold = 10 ** (-40)\n",
    "theta = init_theta_LWR(X)\n",
    "reg_lambda = 10 ** (-22)\n",
    "LWRBand = float(20 / 546)\n",
    "\n",
    "input_var = [1, 4000,2 ,1 ,1 ,1 ,1 ,0 ,0 ,0 ,0 ,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_col = np.mean(X, axis=0)\n",
    "std_col = np.std(X, axis=0)\n",
    "for i in range(1, X.shape[1]) :\n",
    "    for j in range(X.shape[0]) :\n",
    "        X[j][i] = X[j][i] - mean_col[i]\n",
    "        X[j][i] = X[j][i] / std_col[i]\n",
    "            \n",
    "# apply this for input as well\n",
    "for i in range(1, X.shape[1]): \n",
    "    input_var[i] = input_var[i] - mean_col[i]\n",
    "    input_var[i] = input_var[i] / std_col[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations:  54\n",
      "Final cost:  9.060006210999761e-18\n",
      "Final theta:  [ 3101.57188523 -2362.88555452 -4063.51498634 -1766.32905256\n",
      " -2888.0508516   1256.72655661  6672.96972752 -2275.01549192\n",
      "  -679.41165693 -2112.27513615 -2495.29173226 -1716.32170698]\n",
      "Predicted value :  34454.59427890817\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# locally weighted regression functions\n",
    "\n",
    "W = get_weights(X, input_var, LWRBand)\n",
    "LWRTheta = LWRGD(X, Y, theta, alpha, W, threshold, reg_lambda)\n",
    "print(\"Final cost: \", LWRCost(X, Y, LWRTheta, W, reg_lambda))\n",
    "print(\"Final theta: \", LWRTheta)\n",
    "\n",
    "print(\"Predicted value : \", np.dot(np.transpose(input_var), LWRTheta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cost:  0.0014490362489622119\n",
      "Final theta:  [ 3.379200e+04 -3.303125e+02 -1.280000e+02 -2.560000e+02  4.725000e+01\n",
      " -1.665000e+02  0.000000e+00  0.000000e+00 -1.275000e+01 -1.100000e+01\n",
      "  0.000000e+00  6.400000e+01]\n",
      "Predicted value :  34144.29688021046\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for normal equation\n",
    "LWRTheta_Normal = LWR_Normal(X, W, Y)\n",
    "print(\"Final cost: \", LWRCost(X, Y, LWRTheta_Normal, W, reg_lambda))\n",
    "print(\"Final theta: \", LWRTheta_Normal)\n",
    "\n",
    "print(\"Predicted value : \", np.dot(np.transpose(input_var), LWRTheta_Normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
